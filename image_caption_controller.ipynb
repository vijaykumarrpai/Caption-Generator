{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from image_caption_generator import ImageCaptionGenerator\n",
    "from flask import Flask, render_template, request, redirect, url_for, send_from_directory, flash\n",
    "from werkzeug.utils import secure_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "UPLOAD_FOLDER = os.path.join('D:\\\\', 'Study', 'Dataset', 'Flickr8k_Dataset', 'Flicker8k_Dataset')\n",
    "ALLOWED_EXTENSIONS = set(['png', 'jpg', 'jpeg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "app = Flask(__name__)\n",
    "app.config['UPLOAD_FOLDER'] = UPLOAD_FOLDER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def allowed_file(filename):\n",
    "    return '.' in filename and \\\n",
    "           filename.rsplit('.', 1)[1].lower() in ALLOWED_EXTENSIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.route('/', methods=['GET', 'POST'])\n",
    "def upload_file():\n",
    "    if request.method == 'POST':\n",
    "        if 'file' not in request.files:\n",
    "            flash('No file part')\n",
    "            return redirect(request.url)\n",
    "        file = request.files['file']\n",
    "        if file.filename == '':\n",
    "            flash('No selected file')\n",
    "            return redirect(request.url)\n",
    "        if file and allowed_file(file.filename):\n",
    "            filename = secure_filename(file.filename)\n",
    "            file.save(os.path.join(app.config['UPLOAD_FOLDER'], filename))\n",
    "            return redirect(url_for('get_caption',\n",
    "                                    filename=filename))\n",
    "    return render_template(\"index.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.route('/caption/<path:filename>', methods=['GET'])\n",
    "def get_caption(filename):\n",
    "    imgcptgen = ImageCaptionGenerator()\n",
    "    full_filename = os.path.join(app.config['UPLOAD_FOLDER'], filename)\n",
    "    model, tokenizer, max_length = imgcptgen.testing_params()\n",
    "    caption = imgcptgen.test(model, tokenizer, max_length, full_filename)\n",
    "    return render_template(\"caption.html\", captioned_image = 'Flicker8k_Dataset/' + filename, caption = caption)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://localhost:5000/ (Press CTRL+C to quit)\n",
      "127.0.0.1 - - [24/Mar/2020 20:20:46] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [24/Mar/2020 20:20:54] \"\u001b[32mPOST / HTTP/1.1\u001b[0m\" 302 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features already extracted into 'features.plk' file.\n",
      "Loaded Descriptions: 8092 \n",
      "Vocabulary Size: 8763\n",
      "Training Images Dataset: 6000\n",
      "Descriptions for Training Images Dataset: 6000\n",
      "Extracted Training Image Features: 6000\n",
      "Test Images Dataset: 1000\n",
      "Descriptions for Test Images Dataset: 1000\n",
      "Extracted Test Image Features: 1000\n",
      "Tokenizer already created and saved into 'tokenizer.pkl'\n",
      "Loading tokenizer ...\n",
      "Vocabulary Size: 7579\n",
      "Maximum Description Length (in words): 34\n",
      "Loading latest model - D:/Study/Caption-Generator/model_18.h5\n",
      "WARNING:tensorflow:From C:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Anaconda\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From C:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Using vgg16 model to extract features ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [24/Mar/2020 20:21:35] \"\u001b[37mGET /caption/1009434119_febe49276a.jpg HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [24/Mar/2020 20:21:36] \"\u001b[36mGET /static/Flicker8k_Dataset/1009434119_febe49276a.jpg HTTP/1.1\u001b[0m\" 304 -\n",
      "127.0.0.1 - - [24/Mar/2020 20:21:52] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [24/Mar/2020 20:22:10] \"\u001b[32mPOST / HTTP/1.1\u001b[0m\" 302 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features already extracted into 'features.plk' file.\n",
      "Loaded Descriptions: 8092 \n",
      "Vocabulary Size: 8763\n",
      "Training Images Dataset: 6000\n",
      "Descriptions for Training Images Dataset: 6000\n",
      "Extracted Training Image Features: 6000\n",
      "Test Images Dataset: 1000\n",
      "Descriptions for Test Images Dataset: 1000\n",
      "Extracted Test Image Features: 1000\n",
      "Tokenizer already created and saved into 'tokenizer.pkl'\n",
      "Loading tokenizer ...\n",
      "Vocabulary Size: 7579\n",
      "Maximum Description Length (in words): 34\n",
      "Loading latest model - D:/Study/Caption-Generator/model_18.h5\n",
      "Using vgg16 model to extract features ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [24/Mar/2020 20:22:34] \"\u001b[37mGET /caption/667626_18933d713e.jpg HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [24/Mar/2020 20:22:35] \"\u001b[37mGET /static/Flicker8k_Dataset/667626_18933d713e.jpg HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [24/Mar/2020 20:22:45] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [24/Mar/2020 20:22:56] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [24/Mar/2020 20:23:03] \"\u001b[32mPOST / HTTP/1.1\u001b[0m\" 302 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features already extracted into 'features.plk' file.\n",
      "Loaded Descriptions: 8092 \n",
      "Vocabulary Size: 8763\n",
      "Training Images Dataset: 6000\n",
      "Descriptions for Training Images Dataset: 6000\n",
      "Extracted Training Image Features: 6000\n",
      "Test Images Dataset: 1000\n",
      "Descriptions for Test Images Dataset: 1000\n",
      "Extracted Test Image Features: 1000\n",
      "Tokenizer already created and saved into 'tokenizer.pkl'\n",
      "Loading tokenizer ...\n",
      "Vocabulary Size: 7579\n",
      "Maximum Description Length (in words): 34\n",
      "Loading latest model - D:/Study/Caption-Generator/model_18.h5\n",
      "Using vgg16 model to extract features ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [24/Mar/2020 20:23:31] \"\u001b[37mGET /caption/example.jpg HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [24/Mar/2020 20:23:32] \"\u001b[33mGET /static/Flicker8k_Dataset/example.jpg HTTP/1.1\u001b[0m\" 404 -\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    from werkzeug.serving import run_simple\n",
    "    run_simple(\"localhost\", 5000, app)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
